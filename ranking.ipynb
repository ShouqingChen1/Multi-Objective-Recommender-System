{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install polars\n","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:38:24.508347Z","iopub.execute_input":"2023-01-31T14:38:24.508596Z","iopub.status.idle":"2023-01-31T14:38:30.256085Z","shell.execute_reply.started":"2023-01-31T14:38:24.508572Z","shell.execute_reply":"2023-01-31T14:38:30.255178Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting polars\n  Downloading polars-0.16.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.8/site-packages (from polars) (4.4.0)\nInstalling collected packages: polars\nSuccessfully installed polars-0.16.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyarrow\n!pip install fastparquet","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:38:30.257905Z","iopub.execute_input":"2023-01-31T14:38:30.258234Z","iopub.status.idle":"2023-01-31T14:38:41.280303Z","shell.execute_reply.started":"2023-01-31T14:38:30.258204Z","shell.execute_reply":"2023-01-31T14:38:41.279396Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pyarrow\n  Downloading pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/site-packages (from pyarrow) (1.24.1)\nInstalling collected packages: pyarrow\nSuccessfully installed pyarrow-11.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mCollecting fastparquet\n  Downloading fastparquet-2023.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from fastparquet) (22.0)\nRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.8/site-packages (from fastparquet) (1.5.2)\nCollecting cramjam>=2.3\n  Downloading cramjam-2.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fsspec\n  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 KB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/site-packages (from fastparquet) (1.24.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas>=1.5.0->fastparquet) (2022.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\nInstalling collected packages: fsspec, cramjam, fastparquet\nSuccessfully installed cramjam-2.6.2 fastparquet-2023.1.0 fsspec-2023.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import polars as pl\nimport pandas as pd, numpy as np\nfrom tqdm.notebook import tqdm\nimport os, sys, pickle, glob, gc\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:38:41.281625Z","iopub.execute_input":"2023-01-31T14:38:41.281940Z","iopub.status.idle":"2023-01-31T14:38:43.013968Z","shell.execute_reply.started":"2023-01-31T14:38:41.281909Z","shell.execute_reply":"2023-01-31T14:38:43.013136Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pl.read_parquet(\"../input/otto-train-and-test-data-for-local-validation/train.parquet\")\nvalid = pl.read_parquet(\"../input/otto-train-and-test-data-for-local-validation/test.parquet\")\nvalid_labels = pl.read_parquet(\"../input/otto-train-and-test-data-for-local-validation/test_labels.parquet\")","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:38:43.016270Z","iopub.execute_input":"2023-01-31T14:38:43.016621Z","iopub.status.idle":"2023-01-31T14:38:53.455420Z","shell.execute_reply.started":"2023-01-31T14:38:43.016595Z","shell.execute_reply":"2023-01-31T14:38:53.454573Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"type_labels = {'clicks':0, 'carts':1, 'orders':2}\ndef load_test():    \n    dfs = []\n    for e, chunk_file in enumerate(glob.glob('../input/otto-chunk-data-inparquet-format/test_parquet/*')):\n        chunk = pd.read_parquet(chunk_file)\n        chunk['ts'] = (chunk['ts']/1000).astype('int32')\n        chunk['type'] = chunk['type'].map(type_labels).astype('u1')\n        chunk['session'] = chunk['session'].astype('int32')\n        chunk['aid'] = chunk['aid'].astype('int32')\n        dfs.append(chunk)\n    return pd.concat(dfs).reset_index(drop=True) #.astype({\"ts\": \"datetime64[ms]\"})\n\ntest = load_test()\nprint('Test data has shape',test.shape)\ntest = pl.from_pandas(test)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:38:53.456500Z","iopub.execute_input":"2023-01-31T14:38:53.456779Z","iopub.status.idle":"2023-01-31T14:38:55.892236Z","shell.execute_reply.started":"2023-01-31T14:38:53.456754Z","shell.execute_reply":"2023-01-31T14:38:55.891379Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Test data has shape (6928123, 4)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"shape: (5, 4)\n┌──────────┬────────┬────────────┬──────┐\n│ session  ┆ aid    ┆ ts         ┆ type │\n│ ---      ┆ ---    ┆ ---        ┆ ---  │\n│ i32      ┆ i32    ┆ i32        ┆ u8   │\n╞══════════╪════════╪════════════╪══════╡\n│ 13099779 ┆ 245308 ┆ 1661795832 ┆ 0    │\n│ 13099779 ┆ 245308 ┆ 1661795862 ┆ 1    │\n│ 13099779 ┆ 972319 ┆ 1661795888 ┆ 0    │\n│ 13099779 ┆ 972319 ┆ 1661795898 ┆ 1    │\n│ 13099779 ┆ 245308 ┆ 1661795907 ┆ 0    │\n└──────────┴────────┴────────────┴──────┘","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\n    .dataframe td {\n        white-space: pre;\n    }\n\n    .dataframe td {\n        padding-top: 0;\n    }\n\n    .dataframe td {\n        padding-bottom: 0;\n    }\n\n    .dataframe td {\n        line-height: 95%;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n<small>shape: (5, 4)</small>\n<thead>\n<tr>\n<th>\nsession\n</th>\n<th>\naid\n</th>\n<th>\nts\n</th>\n<th>\ntype\n</th>\n</tr>\n<tr>\n<td>\ni32\n</td>\n<td>\ni32\n</td>\n<td>\ni32\n</td>\n<td>\nu8\n</td>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\n13099779\n</td>\n<td>\n245308\n</td>\n<td>\n1661795832\n</td>\n<td>\n0\n</td>\n</tr>\n<tr>\n<td>\n13099779\n</td>\n<td>\n245308\n</td>\n<td>\n1661795862\n</td>\n<td>\n1\n</td>\n</tr>\n<tr>\n<td>\n13099779\n</td>\n<td>\n972319\n</td>\n<td>\n1661795888\n</td>\n<td>\n0\n</td>\n</tr>\n<tr>\n<td>\n13099779\n</td>\n<td>\n972319\n</td>\n<td>\n1661795898\n</td>\n<td>\n1\n</td>\n</tr>\n<tr>\n<td>\n13099779\n</td>\n<td>\n245308\n</td>\n<td>\n1661795907\n</td>\n<td>\n0\n</td>\n</tr>\n</tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Generating the item features","metadata":{}},{"cell_type":"code","source":"# {'aid':'count', 'session':'nunique', 'type': 'mean'}\nitem_features = pl.concat([train, valid]).groupby('aid').agg([\n    pl.count(\"aid\").alias(\"item_item_count\"), \n    pl.n_unique(\"session\").alias(\"item_user_count\"), \n    pl.mean(\"type\").alias(\"item_buy_ratio\").cast(pl.Float32)\n])\nitem_features.write_parquet('item_features.parquet')\n# TEST\nitem_features_test = pl.concat([train, test]).groupby('aid').agg([\n    pl.count(\"aid\").alias(\"item_item_count\"), \n    pl.n_unique(\"session\").alias(\"item_user_count\"), \n    pl.mean(\"type\").alias(\"item_buy_ratio\").cast(pl.Float32)\n])\nitem_features_test.write_parquet('item_features_test.parquet')","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:38:55.893477Z","iopub.execute_input":"2023-01-31T14:38:55.893791Z","iopub.status.idle":"2023-01-31T14:39:02.867945Z","shell.execute_reply.started":"2023-01-31T14:38:55.893764Z","shell.execute_reply":"2023-01-31T14:39:02.867054Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Generating the user features","metadata":{}},{"cell_type":"code","source":"# {'session':'count','aid':'nunique','type':'mean'}\nuser_features = valid.groupby('session').agg([\n    pl.count(\"session\").alias(\"user_user_count\"),\n    pl.n_unique(\"aid\").alias(\"user_item_count\"),\n    pl.mean(\"type\").alias(\"user_buy_ratio\").cast(pl.Float32)\n])\nuser_features.write_parquet('user_features.parquet')\n\nuser_features_test = test.groupby('session').agg([\n    pl.count(\"session\").alias(\"user_user_count\"),\n    pl.n_unique(\"aid\").alias(\"user_item_count\"),\n    pl.mean(\"type\").alias(\"user_buy_ratio\").cast(pl.Float32)\n])\nuser_features.write_parquet('user_features_test.parquet')","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:39:02.869162Z","iopub.execute_input":"2023-01-31T14:39:02.869471Z","iopub.status.idle":"2023-01-31T14:39:03.910569Z","shell.execute_reply.started":"2023-01-31T14:39:02.869447Z","shell.execute_reply":"2023-01-31T14:39:03.909694Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Generating the user item features","metadata":{}},{"cell_type":"code","source":"%%time\ndef get_time_diff(valid_filter):\n    ts_diff_1 = valid_filter['ts'][-1]-valid_filter['ts'] \n    ts_diff_3 = valid_filter['ts'].shift(-1)-valid_filter['ts']\n    ts_diff_2 = ts_diff_3.shift(-1)\n    ts_diff_4 = valid_filter['ts'][-1] - valid_filter['ts'] \n    ts_diff_5 = valid_filter['ts'] -valid_filter['ts'][0]\n    valid_filter = valid_filter.with_column(pl.lit(ts_diff_1).alias('ts_diff_1'))\n    valid_filter = valid_filter.with_column(pl.lit(ts_diff_2).alias('ts_diff_2'))\n    valid_filter = valid_filter.with_column(pl.lit(ts_diff_3).alias('ts_diff_3'))\n    valid_filter = valid_filter.with_column(pl.lit(ts_diff_4).alias('ts_diff_4'))\n    valid_filter = valid_filter.with_column(pl.lit(ts_diff_5).alias('ts_diff_5'))\n\n    return valid_filter\n\nuser_item_features = valid.sort([\"session\", \"ts\"]).groupby(['session']).apply(lambda x: get_time_diff(x))\nuser_item_features_test =  test.sort([\"session\", \"ts\"]).groupby(['session']).apply(lambda x: get_time_diff(x))","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:39:03.932158Z","iopub.execute_input":"2023-01-31T14:39:03.932480Z","iopub.status.idle":"2023-01-31T15:09:08.999714Z","shell.execute_reply.started":"2023-01-31T14:39:03.932457Z","shell.execute_reply":"2023-01-31T15:09:08.998840Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"<timed exec>:7: DeprecationWarning: `with_column` has been deprecated in favor of `with_columns`. This method will be removed in version 0.17.0\n<timed exec>:8: DeprecationWarning: `with_column` has been deprecated in favor of `with_columns`. This method will be removed in version 0.17.0\n<timed exec>:9: DeprecationWarning: `with_column` has been deprecated in favor of `with_columns`. This method will be removed in version 0.17.0\n<timed exec>:10: DeprecationWarning: `with_column` has been deprecated in favor of `with_columns`. This method will be removed in version 0.17.0\n<timed exec>:11: DeprecationWarning: `with_column` has been deprecated in favor of `with_columns`. This method will be removed in version 0.17.0\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 3h 10min 18s, sys: 27min 32s, total: 3h 37min 50s\nWall time: 30min 5s\n","output_type":"stream"}]},{"cell_type":"code","source":"event_paths = {\n    \"clicks\": \"/kaggle/input/ott0cgv5/valid_click_candidates_v5.parquet\",\n    \"carts\": \"/kaggle/input/ott0cgv5/valid_carts_candidates_v5..parquet\",\n    \"buys\": \"/kaggle/input/ott0cgv5/valid_buys_candidates_v5..parquet\"\n}\n\nevent_paths_test = {\n    \"clicks\": \"../input/ott0cgv5/test_click_candidates_v5.parquet\",\n    \"carts\": \"../input/ott0cgv5/test_carts_candidates_v5.parquet\",\n    \"buys\": \"../input/ott0cgv5/test_buys_candidates_v5.parquet\"\n}","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:09:09.292324Z","iopub.status.idle":"2023-01-31T15:09:09.292667Z","shell.execute_reply.started":"2023-01-31T15:09:09.292499Z","shell.execute_reply":"2023-01-31T15:09:09.292514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train, valid\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:09:09.294148Z","iopub.status.idle":"2023-01-31T15:09:09.294581Z","shell.execute_reply.started":"2023-01-31T15:09:09.294408Z","shell.execute_reply":"2023-01-31T15:09:09.294424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the ranker","metadata":{}},{"cell_type":"code","source":"!pip install xgboost","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:09:09.295520Z","iopub.status.idle":"2023-01-31T15:09:09.295846Z","shell.execute_reply.started":"2023-01-31T15:09:09.295675Z","shell.execute_reply":"2023-01-31T15:09:09.295690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install scikit-learn","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:09:09.296720Z","iopub.status.idle":"2023-01-31T15:09:09.297059Z","shell.execute_reply.started":"2023-01-31T15:09:09.296880Z","shell.execute_reply":"2023-01-31T15:09:09.296896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import GroupKFold\n\n\ndef train_ranker(event, df_cands, n_splits=5):\n    \n    skf = GroupKFold(n_splits=n_splits)\n    FEATURES = [\n        'session', 'item_item_count', 'item_user_count', 'item_buy_ratio', 'user_user_count', 'user_item_count', 'user_buy_ratio',\n        'item_clicked','ts_diff_1','ts_diff_2','ts_diff_3','ts_diff_4','ts_diff_5'\n    ]\n    TARGET = \"target\"\n    for fold,(train_idx, valid_idx) in enumerate(skf.split(df_cands, df_cands['target'], groups=df_cands['session'])):\n\n        X_train = df_cands.loc[train_idx, FEATURES]\n        y_train = df_cands.loc[train_idx, TARGET]\n        X_valid = df_cands.loc[valid_idx, FEATURES]\n        y_valid = df_cands.loc[valid_idx, TARGET]\n\n        X_train = X_train.sort_values(\"session\").reset_index(drop=True)\n        X_valid = X_valid.sort_values(\"session\").reset_index(drop=True)\n\n        train_group = X_train.groupby('session').session.agg('count').values\n        valid_group = X_valid.groupby('session').session.agg('count').values\n\n        X_train = X_train.drop([\"session\"], axis=1)\n        X_valid = X_valid.drop([\"session\"], axis=1)\n\n        dtrain = xgb.DMatrix(X_train, y_train, group=train_group) # [50] * (len(train_idx)//50) \n        dvalid = xgb.DMatrix(X_valid, y_valid, group=valid_group) # [50] * (len(valid_idx)//50)\n        xgb_parms = {\n            'objective':'rank:pairwise', \n            'tree_method':'hist',\n            'random_state': 42, \n            'learning_rate': 0.1,\n            \"colsample_bytree\": 0.8, \n            'eta': 0.05, \n            'max_depth': 6,\n            'subsample': 0.75,\n            # n_estimators=110,\n        }\n        model = xgb.train(\n            xgb_parms, \n            dtrain=dtrain,\n            evals=[(dtrain,'train'), (dvalid,'valid')],\n            num_boost_round=100,\n            verbose_eval=20\n        )\n        model.save_model(f'XGB_fold{fold}_{event}.xgb')\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:09:09.298392Z","iopub.status.idle":"2023-01-31T15:09:09.298734Z","shell.execute_reply.started":"2023-01-31T15:09:09.298558Z","shell.execute_reply":"2023-01-31T15:09:09.298574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Ranker","metadata":{}},{"cell_type":"code","source":"%%time\nNEGATIVE_FRAC = 0.15\nNEGATIVE_FRAC_DICT = {'clicks':0.15, 'carts':0.03,'buys':0.03}\nfor event, path in event_paths.items():\n    print(f\"Started ranking model for: {event}\")\n    # Reading the labels\n    df_cands = pl.read_parquet(path)\n    # specify for my data\n    version = df_cands['session'].apply(lambda x: int(str(x).split('_')[0]))\n    df_cands = df_cands.with_column(pl.lit(version).alias('session'))\n    \n    df_cands = df_cands.explode(\"labels\").with_columns([\n        pl.col(\"session\").cast(pl.Int32),\n        pl.col(\"labels\").cast(pl.Int32).alias(\"aid\")\n    ]).drop(\"labels\").unique(subset=[\"session\", \"aid\"])\n    # Joining the item features\n    df_cands = df_cands.join(item_features, on='aid', how='left').fill_nan(-1)\n    # Joining the user features\n    df_cands = df_cands.join(user_features, on='session', how='left').fill_nan(-1)\n    # Joining the user item features\n    df_cands = df_cands.join(user_item_features, on=['session','aid'], how='left').fill_nan(-1)\n    cand_labels = valid_labels.filter(valid_labels[\"type\"] == event).explode(\"ground_truth\").with_columns([\n        pl.col(\"session\").cast(pl.Int32),\n        pl.col(\"ground_truth\").cast(pl.Int32)# .alias(\"aid\")\n    ]).rename({\"ground_truth\": \"aid\"})\n    cand_labels = cand_labels.with_column(pl.lit(1).alias(\"target\").cast(pl.Int8)).drop(\"type\")\n    # Joining the labels\n    df_cands = df_cands.join(cand_labels, on=[\"session\", \"aid\"], how=\"left\").fill_null(0)\n    # Negative sampling\n    df_cands = pl.concat([\n        df_cands.filter(df_cands[\"target\"] == 0).sample(frac=NEGATIVE_FRAC_DICT[event], seed=42),\n        df_cands.filter(df_cands[\"target\"] == 1)\n    ])\n    print(df_cands.groupby(\"target\").agg(pl.count()))\n    df_cands = df_cands.to_pandas()\n    df_cands = df_cands.sort_values(\"session\").reset_index(drop=True)\n    print(f\"Event: {event} - started training...\")\n    train_ranker(event, df_cands)\n    del df_cands, cand_labels\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:09:09.299600Z","iopub.status.idle":"2023-01-31T15:09:09.300010Z","shell.execute_reply.started":"2023-01-31T15:09:09.299793Z","shell.execute_reply":"2023-01-31T15:09:09.299818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"%%time\n#  stage-1： test candidate generation & FE\n# NEGATIVE_FRAC = 0.15\ntest_candidates_whole = {}\nfor event, path in event_paths_test.items():\n    print(f\"Started building test_infer data for: {event}\")\n    # Reading the candidates\n    df_cands = pl.read_parquet(path)\n    # specify for my data\n    version = df_cands['session'].apply(lambda x: int(str(x).split('_')[0]))\n    df_cands = df_cands.with_column(pl.lit(version).alias('session'))\n    \n    df_cands = df_cands.explode(\"labels\").with_columns([\n        pl.col(\"session\").cast(pl.Int32),\n        pl.col(\"labels\").cast(pl.Int32).alias(\"aid\")\n    ]).drop(\"labels\").unique(subset=[\"session\", \"aid\"])\n    # Joining the item features\n    df_cands = df_cands.join(item_features_test, on='aid', how='left').fill_nan(-1)\n    # Joining the user features\n    df_cands = df_cands.join(user_features_test, on='session', how='left').fill_nan(-1)\n    # Joining the user item features\n    df_cands = df_cands.join(user_item_features_test, on=['session','aid'], how='left').fill_nan(-1)\n    df_cands = df_cands.to_pandas()\n    df_cands = df_cands.sort_values(\"session\").reset_index(drop=True)\n    print(f\"Event: {event} - started building cg...\")\n    test_candidates_whole[event] = df_cands.fillna(0)\n    del df_cands\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:09:09.301041Z","iopub.status.idle":"2023-01-31T15:09:09.301412Z","shell.execute_reply.started":"2023-01-31T15:09:09.301221Z","shell.execute_reply":"2023-01-31T15:09:09.301238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stage-2： ranker pred \npred_df = pd.DataFrame()\n# pred_df.columns = [\"session_type\", \"labels\"]\nFEATURES = [\n        'item_item_count', 'item_user_count', 'item_buy_ratio', 'user_user_count', 'user_item_count', 'user_buy_ratio',\n    'item_clicked','ts_diff_1','ts_diff_2','ts_diff_3','ts_diff_4','ts_diff_5'\n    ]\nfor event, test_candidates in test_candidates_whole.items():\n    print(f\"Event: {event} - started pred...\")\n    preds = np.zeros(len(test_candidates))\n    for fold in range(5):\n        model = xgb.Booster()\n#         model.load_model(f'/kaggle/input/gbdtrankingoutput/XGB_fold{fold}_{event}.xgb')\n        model.load_model(f'XGB_fold{fold}_{event}.xgb')\n#         model.set_param({'predictor': 'gpu_predictor'})\n        dtest = xgb.DMatrix(data=test_candidates[FEATURES])\n        preds += model.predict(dtest)/5\n    predictions = test_candidates[['session','aid']].copy()\n    predictions['pred'] = preds\n\n    predictions = predictions.sort_values(['session','pred'], ascending=[True,False]).reset_index(drop=True)\n    predictions['n'] = predictions.groupby('session')['aid'].cumcount().astype('int8')\n    predictions = predictions.loc[predictions.n<20]\n    sub = predictions.groupby('session')['aid'].apply(list)\n    sub = sub.to_frame().reset_index()\n    sub['aid'] = sub['aid'].apply(lambda x: \" \".join(map(str,x)))\n    sub.columns = ['session_type','labels']\n    sub.session_type = sub.session_type.astype('str')+ '_clicks'\n    pred_df = pred_df.append(sub) \n    del sub \n    _ = gc.collect()\n# sub     \npred_df.to_csv(\"submission.csv\", index=False)\npred_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:09:09.302635Z","iopub.status.idle":"2023-01-31T15:09:09.302963Z","shell.execute_reply.started":"2023-01-31T15:09:09.302790Z","shell.execute_reply":"2023-01-31T15:09:09.302812Z"},"trusted":true},"execution_count":null,"outputs":[]}]}