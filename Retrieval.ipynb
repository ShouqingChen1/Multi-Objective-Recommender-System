{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e491ca45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T12:33:04.328415Z",
     "iopub.status.busy": "2023-01-30T12:33:04.327577Z",
     "iopub.status.idle": "2023-01-30T12:33:04.332661Z",
     "shell.execute_reply": "2023-01-30T12:33:04.331955Z"
    },
    "papermill": {
     "duration": 0.017525,
     "end_time": "2023-01-30T12:33:04.334733",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.317208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VER = 5\n",
    "\n",
    "# import pandas as pd, numpy as np\n",
    "# from tqdm.notebook import tqdm\n",
    "# import os, sys, pickle, glob, gc\n",
    "# from collections import Counter\n",
    "# import  itertools\n",
    "# import cudf, itertools\n",
    "# print('We will use RAPIDS version',cudf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548c4c3",
   "metadata": {
    "papermill": {
     "duration": 0.007857,
     "end_time": "2023-01-30T12:33:04.350873",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.343016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compute Three Co-visitation Matrices with RAPIDS\n",
    "We will compute 3 co-visitation matrices using RAPIDS cuDF on GPU. This is 30x faster than using Pandas CPU like other public notebooks! For maximum speed, set the variable `DISK_PIECES` to the smallest number possible based on the GPU you are using without incurring memory errors. If you run this code offline with 32GB GPU ram, then you can use `DISK_PIECES = 1` and compute each co-visitation matrix in almost 1 minute! Kaggle's GPU only has 16GB ram, so we use `DISK_PIECES = 4` and it takes an amazing 3 minutes each! Below are some of the tricks to speed up computation\n",
    "* Use RAPIDS cuDF GPU instead of Pandas CPU\n",
    "* Read disk once and save in CPU RAM for later GPU multiple use\n",
    "* Process largest amount of data possible on GPU at one time\n",
    "* Merge data in two stages. Multiple small to single medium. Multiple medium to single large.\n",
    "* Write result as parquet instead of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397abff8",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-01-30T12:33:04.367493Z",
     "iopub.status.busy": "2023-01-30T12:33:04.367192Z",
     "iopub.status.idle": "2023-01-30T12:33:04.371571Z",
     "shell.execute_reply": "2023-01-30T12:33:04.370892Z"
    },
    "papermill": {
     "duration": 0.01491,
     "end_time": "2023-01-30T12:33:04.373497",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.358587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # CACHE FUNCTIONS\n",
    "# def read_file(f):\n",
    "#     return cudf.DataFrame( data_cache[f] )\n",
    "# def read_file_to_cache(f):\n",
    "#     df = pd.read_parquet(f)\n",
    "#     df.ts = (df.ts/1000).astype('int32')\n",
    "#     df['type'] = df['type'].map(type_labels).astype('int8')\n",
    "#     return df\n",
    "\n",
    "# # CACHE THE DATA ON CPU BEFORE PROCESSING ON GPU\n",
    "# data_cache = {}\n",
    "# type_labels = {'clicks':0, 'carts':1, 'orders':2}\n",
    "# files = glob.glob('../input/otto-chunk-data-inparquet-format/*_parquet/*')\n",
    "# for f in files: data_cache[f] = read_file_to_cache(f)\n",
    "\n",
    "# # CHUNK PARAMETERS\n",
    "# READ_CT = 5\n",
    "# CHUNK = int( np.ceil( len(files)/6 ))\n",
    "# print(f'We will process {len(files)} files, in groups of {READ_CT} and chunks of {CHUNK}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ff0a8",
   "metadata": {
    "papermill": {
     "duration": 0.007737,
     "end_time": "2023-01-30T12:33:04.389122",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.381385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1) \"Carts Orders\" Co-visitation Matrix - Type Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da546170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T12:33:04.405992Z",
     "iopub.status.busy": "2023-01-30T12:33:04.405476Z",
     "iopub.status.idle": "2023-01-30T12:33:04.411372Z",
     "shell.execute_reply": "2023-01-30T12:33:04.410696Z"
    },
    "papermill": {
     "duration": 0.016847,
     "end_time": "2023-01-30T12:33:04.413345",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.396498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# type_weight = {0:1, 1:6, 2:3}\n",
    "\n",
    "# # USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "# DISK_PIECES = 4\n",
    "# SIZE = 1.86e6/DISK_PIECES\n",
    "\n",
    "# # COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "# for PART in range(DISK_PIECES):\n",
    "#     print()\n",
    "#     print('### DISK PART',PART+1)\n",
    "    \n",
    "#     # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "#     # => OUTER CHUNKS\n",
    "#     for j in range(6):\n",
    "#         a = j*CHUNK\n",
    "#         b = min( (j+1)*CHUNK, len(files) )\n",
    "#         print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "        \n",
    "#         # => INNER CHUNKS\n",
    "#         for k in range(a,b,READ_CT):\n",
    "#             # READ FILE\n",
    "#             df = [read_file(files[k])]\n",
    "#             for i in range(1,READ_CT): \n",
    "#                 if k+i<b: df.append( read_file(files[k+i]) )\n",
    "#             df = cudf.concat(df,ignore_index=True,axis=0)\n",
    "#             df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "#             # USE TAIL OF SESSION\n",
    "#             df = df.reset_index(drop=True)\n",
    "#             df['n'] = df.groupby('session').cumcount()\n",
    "#             df = df.loc[df.n<30].drop('n',axis=1)\n",
    "#             # CREATE PAIRS\n",
    "#             df = df.merge(df,on='session')\n",
    "#             df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "#             # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "#             df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "#             # ASSIGN WEIGHTS\n",
    "#             df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "#             df['wgt'] = df.type_y.map(type_weight)\n",
    "#             df = df[['aid_x','aid_y','wgt']]\n",
    "#             df.wgt = df.wgt.astype('float32')\n",
    "#             df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "#             # COMBINE INNER CHUNKS\n",
    "#             if k==a: tmp2 = df\n",
    "#             else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "#             print(k,', ',end='')\n",
    "#         print()\n",
    "#         # COMBINE OUTER CHUNKS\n",
    "#         if a==0: tmp = tmp2\n",
    "#         else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "#         del tmp2, df\n",
    "#         gc.collect()\n",
    "#     # CONVERT MATRIX TO DICTIONARY\n",
    "#     tmp = tmp.reset_index()\n",
    "#     tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "#     # SAVE TOP 40\n",
    "#     tmp = tmp.reset_index(drop=True)\n",
    "#     tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "#     tmp = tmp.loc[tmp.n<15].drop('n',axis=1)\n",
    "#     # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "#     tmp.to_pandas().to_parquet(f'top_15_carts_orders_v{VER}_{PART}.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6602e7e",
   "metadata": {
    "papermill": {
     "duration": 0.007785,
     "end_time": "2023-01-30T12:33:04.428942",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.421157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2) \"Buy2Buy\" Co-visitation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c1ec68",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-01-30T12:33:04.445626Z",
     "iopub.status.busy": "2023-01-30T12:33:04.445362Z",
     "iopub.status.idle": "2023-01-30T12:33:04.451221Z",
     "shell.execute_reply": "2023-01-30T12:33:04.450561Z"
    },
    "papermill": {
     "duration": 0.016691,
     "end_time": "2023-01-30T12:33:04.453118",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.436427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "# DISK_PIECES = 1\n",
    "# SIZE = 1.86e6/DISK_PIECES\n",
    "\n",
    "# # COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "# for PART in range(DISK_PIECES):\n",
    "#     print()\n",
    "#     print('### DISK PART',PART+1)\n",
    "    \n",
    "#     # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "#     # => OUTER CHUNKS\n",
    "#     for j in range(6):\n",
    "#         a = j*CHUNK\n",
    "#         b = min( (j+1)*CHUNK, len(files) )\n",
    "#         print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "        \n",
    "#         # => INNER CHUNKS\n",
    "#         for k in range(a,b,READ_CT):\n",
    "#             # READ FILE\n",
    "#             df = [read_file(files[k])]\n",
    "#             for i in range(1,READ_CT): \n",
    "#                 if k+i<b: df.append( read_file(files[k+i]) )\n",
    "#             df = cudf.concat(df,ignore_index=True,axis=0)\n",
    "#             df = df.loc[df['type'].isin([1,2])] # ONLY WANT CARTS AND ORDERS\n",
    "#             df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "#             # USE TAIL OF SESSION\n",
    "#             df = df.reset_index(drop=True)\n",
    "#             df['n'] = df.groupby('session').cumcount()\n",
    "#             df = df.loc[df.n<30].drop('n',axis=1)\n",
    "#             # CREATE PAIRS\n",
    "#             df = df.merge(df,on='session')\n",
    "#             df = df.loc[ ((df.ts_x - df.ts_y).abs()< 14 * 24 * 60 * 60) & (df.aid_x != df.aid_y) ] # 14 DAYS\n",
    "#             # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "#             df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "#             # ASSIGN WEIGHTS\n",
    "#             df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "#             df['wgt'] = 1\n",
    "#             df = df[['aid_x','aid_y','wgt']]\n",
    "#             df.wgt = df.wgt.astype('float32')\n",
    "#             df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "#             # COMBINE INNER CHUNKS\n",
    "#             if k==a: tmp2 = df\n",
    "#             else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "#             print(k,', ',end='')\n",
    "#         print()\n",
    "#         # COMBINE OUTER CHUNKS\n",
    "#         if a==0: tmp = tmp2\n",
    "#         else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "#         del tmp2, df\n",
    "#         gc.collect()\n",
    "#     # CONVERT MATRIX TO DICTIONARY\n",
    "#     tmp = tmp.reset_index()\n",
    "#     tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "#     # SAVE TOP 40\n",
    "#     tmp = tmp.reset_index(drop=True)\n",
    "#     tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "#     tmp = tmp.loc[tmp.n<15].drop('n',axis=1)\n",
    "#     # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "#     tmp.to_pandas().to_parquet(f'top_15_buy2buy_v{VER}_{PART}.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11794e1",
   "metadata": {
    "papermill": {
     "duration": 0.007878,
     "end_time": "2023-01-30T12:33:04.468826",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.460948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3) \"Clicks\" Co-visitation Matrix - Time Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f80742",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-01-30T12:33:04.485306Z",
     "iopub.status.busy": "2023-01-30T12:33:04.485069Z",
     "iopub.status.idle": "2023-01-30T12:33:04.490798Z",
     "shell.execute_reply": "2023-01-30T12:33:04.490133Z"
    },
    "papermill": {
     "duration": 0.016447,
     "end_time": "2023-01-30T12:33:04.492644",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.476197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "# DISK_PIECES = 4\n",
    "# SIZE = 1.86e6/DISK_PIECES\n",
    "\n",
    "# # COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "# for PART in range(DISK_PIECES):\n",
    "#     print()\n",
    "#     print('### DISK PART',PART+1)\n",
    "    \n",
    "#     # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "#     # => OUTER CHUNKS\n",
    "#     for j in range(6):\n",
    "#         a = j*CHUNK\n",
    "#         b = min( (j+1)*CHUNK, len(files) )\n",
    "#         print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "        \n",
    "#         # => INNER CHUNKS\n",
    "#         for k in range(a,b,READ_CT):\n",
    "#             # READ FILE\n",
    "#             df = [read_file(files[k])]\n",
    "#             for i in range(1,READ_CT): \n",
    "#                 if k+i<b: df.append( read_file(files[k+i]) )\n",
    "#             df = cudf.concat(df,ignore_index=True,axis=0)\n",
    "#             df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "#             # USE TAIL OF SESSION\n",
    "#             df = df.reset_index(drop=True)\n",
    "#             df['n'] = df.groupby('session').cumcount()\n",
    "#             df = df.loc[df.n<30].drop('n',axis=1)\n",
    "#             # CREATE PAIRS\n",
    "#             df = df.merge(df,on='session')\n",
    "#             df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "#             # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "#             df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "#             # ASSIGN WEIGHTS\n",
    "#             df = df[['session', 'aid_x', 'aid_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "#             df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n",
    "#             df = df[['aid_x','aid_y','wgt']]\n",
    "#             df.wgt = df.wgt.astype('float32')\n",
    "#             df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "#             # COMBINE INNER CHUNKS\n",
    "#             if k==a: tmp2 = df\n",
    "#             else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "#             print(k,', ',end='')\n",
    "#         print()\n",
    "#         # COMBINE OUTER CHUNKS\n",
    "#         if a==0: tmp = tmp2\n",
    "#         else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "#         del tmp2, df\n",
    "#         gc.collect()\n",
    "#     # CONVERT MATRIX TO DICTIONARY\n",
    "#     tmp = tmp.reset_index()\n",
    "#     tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "#     # SAVE TOP 40\n",
    "#     tmp = tmp.reset_index(drop=True)\n",
    "#     tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "#     tmp = tmp.loc[tmp.n<20].drop('n',axis=1)\n",
    "#     # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "#     tmp.to_pandas().to_parquet(f'top_20_clicks_v{VER}_{PART}.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5413b06c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T12:33:04.509647Z",
     "iopub.status.busy": "2023-01-30T12:33:04.509409Z",
     "iopub.status.idle": "2023-01-30T12:33:05.806619Z",
     "shell.execute_reply": "2023-01-30T12:33:05.805780Z"
    },
    "papermill": {
     "duration": 1.308603,
     "end_time": "2023-01-30T12:33:05.809198",
     "exception": false,
     "start_time": "2023-01-30T12:33:04.500595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VER = 5\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os, sys, pickle, glob, gc\n",
    "from collections import Counter\n",
    "import itertools\n",
    "# import cudf, itertools\n",
    "# print('We will use RAPIDS version',cudf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081e4e2",
   "metadata": {
    "papermill": {
     "duration": 0.007829,
     "end_time": "2023-01-30T12:33:05.824915",
     "exception": false,
     "start_time": "2023-01-30T12:33:05.817086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2 candidate generation for LGBM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4085389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T12:33:05.854630Z",
     "iopub.status.busy": "2023-01-30T12:33:05.854271Z",
     "iopub.status.idle": "2023-01-30T12:33:17.005241Z",
     "shell.execute_reply": "2023-01-30T12:33:17.004295Z"
    },
    "papermill": {
     "duration": 11.175157,
     "end_time": "2023-01-30T12:33:17.007960",
     "exception": false,
     "start_time": "2023-01-30T12:33:05.832803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\r\n",
      "  Downloading pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/site-packages (from pyarrow) (1.23.4)\r\n",
      "Installing collected packages: pyarrow\r\n",
      "Successfully installed pyarrow-11.0.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting fastparquet\r\n",
      "  Downloading fastparquet-2023.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.8/site-packages (from fastparquet) (1.5.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from fastparquet) (21.3)\r\n",
      "Collecting fsspec\r\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/site-packages (from fastparquet) (1.23.4)\r\n",
      "Collecting cramjam>=2.3\r\n",
      "  Downloading cramjam-2.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas>=1.5.0->fastparquet) (2022.5)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging->fastparquet) (3.0.9)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\r\n",
      "Installing collected packages: fsspec, cramjam, fastparquet\r\n",
      "Successfully installed cramjam-2.6.2 fastparquet-2023.1.0 fsspec-2023.1.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n",
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c77094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T12:33:17.032179Z",
     "iopub.status.busy": "2023-01-30T12:33:17.031597Z",
     "iopub.status.idle": "2023-01-30T12:36:32.282513Z",
     "shell.execute_reply": "2023-01-30T12:36:32.281449Z"
    },
    "papermill": {
     "duration": 195.275215,
     "end_time": "2023-01-30T12:36:32.294904",
     "exception": false,
     "start_time": "2023-01-30T12:33:17.019689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are size of our 3 co-visitation matrices:\n",
      "1837166 1168768 1837166\n",
      "CPU times: user 3min, sys: 6.94 s, total: 3min 7s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "DISK_PIECES = 4\n",
    "SIZE = 1.86e6/DISK_PIECES\n",
    "def pqt_to_dict(df):\n",
    "    return df.groupby('aid_x').aid_y.apply(list).to_dict()\n",
    "# LOAD THREE CO-VISITATION MATRICES\n",
    "top_20_clicks = pqt_to_dict( pd.read_parquet(f'/kaggle/input/candidate-rerank-model-lb-0-575/top_20_clicks_v{VER}_0.pqt') )\n",
    "for k in range(1,DISK_PIECES): \n",
    "    top_20_clicks.update( pqt_to_dict( pd.read_parquet(f'/kaggle/input/candidate-rerank-model-lb-0-575/top_20_clicks_v{VER}_{k}.pqt') ) )\n",
    "top_20_buys = pqt_to_dict( pd.read_parquet(f'/kaggle/input/candidate-rerank-model-lb-0-575/top_15_carts_orders_v{VER}_0.pqt') )\n",
    "for k in range(1,DISK_PIECES): \n",
    "    top_20_buys.update( pqt_to_dict( pd.read_parquet(f'/kaggle/input/candidate-rerank-model-lb-0-575/top_15_carts_orders_v{VER}_{k}.pqt') ) )\n",
    "top_20_buy2buy = pqt_to_dict( pd.read_parquet(f'/kaggle/input/candidate-rerank-model-lb-0-575/top_15_buy2buy_v{VER}_0.pqt') )\n",
    "\n",
    "\n",
    "print('Here are size of our 3 co-visitation matrices:')\n",
    "print( len( top_20_clicks ), len( top_20_buy2buy ), len( top_20_buys ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cec16650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T12:36:32.318012Z",
     "iopub.status.busy": "2023-01-30T12:36:32.317570Z",
     "iopub.status.idle": "2023-01-30T12:36:32.394510Z",
     "shell.execute_reply": "2023-01-30T12:36:32.393668Z"
    },
    "papermill": {
     "duration": 0.091594,
     "end_time": "2023-01-30T12:36:32.396897",
     "exception": false,
     "start_time": "2023-01-30T12:36:32.305303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#type_weight_multipliers = {'clicks': 1, 'carts': 6, 'orders': 3}\n",
    "type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "\n",
    "def suggest_clicks(df):\n",
    "    # USER HISTORY AIDS AND TYPES\n",
    "    aids=df['aid'].tolist()\n",
    "    types = df.type.tolist()\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1] ))\n",
    "    # RERANK CANDIDATES USING WEIGHTS\n",
    "    if len(unique_aids)>=200:\n",
    "        weights=np.logspace(0.1,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(200)]\n",
    "        return sorted_aids\n",
    "    # USE \"CLICKS\" CO-VISITATION MATRIX & unique_aids -> aids\n",
    "    aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in aids if aid in top_20_clicks]))\n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids2).most_common(200) if aid2 not in unique_aids]    \n",
    "    result = unique_aids + top_aids2[:200 - len(unique_aids)]\n",
    "    return result \n",
    "\n",
    "def suggest_buys(df):\n",
    "    # USER HISTORY AIDS AND TYPES\n",
    "    aids=df['aid'].tolist()\n",
    "    types = df.type.tolist()\n",
    "    # UNIQUE AIDS AND UNIQUE BUYS\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1] ))\n",
    "    df = df.loc[(df['type']==1)|(df['type']==2)]\n",
    "    buys=df.aid.tolist()\n",
    "    unique_buys = list(dict.fromkeys( buys[::-1] ))\n",
    "    # RERANK CANDIDATES USING WEIGHTS\n",
    "    if len(unique_aids)>=200:\n",
    "        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        # RERANK CANDIDATES USING \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "        aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n",
    "        for aid in aids3: aids_temp[aid] += 0.1\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(200)]\n",
    "        return sorted_aids\n",
    "    aids_temp = Counter() # add weight in\n",
    "    # USE \"CART ORDER\" CO-VISITATION MATRIX & unique_buys -> buys\n",
    "    aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in aids if aid in top_20_buys]))\n",
    "    for aid in aids2: aids_temp[aid] += 1\n",
    "    # USE \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "    aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in buys if aid in top_20_buy2buy]))\n",
    "    for aid in aids3: aids_temp[aid] += 1\n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [k for k,v in aids_temp.most_common(200) if k not in unique_aids]\n",
    "    result = unique_aids + top_aids2[:200 - len(unique_aids)]\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5fab930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T12:36:32.419296Z",
     "iopub.status.busy": "2023-01-30T12:36:32.419009Z",
     "iopub.status.idle": "2023-01-30T12:36:32.426419Z",
     "shell.execute_reply": "2023-01-30T12:36:32.425524Z"
    },
    "papermill": {
     "duration": 0.021019,
     "end_time": "2023-01-30T12:36:32.428399",
     "exception": false,
     "start_time": "2023-01-30T12:36:32.407380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_df_gen(df):\n",
    "    pred_df_clicks = df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "        lambda x: suggest_clicks(x)\n",
    "    )\n",
    "\n",
    "    # pred_df_carts = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "    #     lambda x: suggest_buys(x)\n",
    "    # )\n",
    "\n",
    "    pred_df_buys = df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "        lambda x: suggest_buys(x)\n",
    "    )\n",
    "    clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n",
    "    orders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n",
    "    carts_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()\n",
    "    \n",
    "    return clicks_pred_df,carts_pred_df,orders_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6477c4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T12:36:32.450941Z",
     "iopub.status.busy": "2023-01-30T12:36:32.450670Z",
     "iopub.status.idle": "2023-01-30T12:36:35.086307Z",
     "shell.execute_reply": "2023-01-30T12:36:35.085261Z"
    },
    "papermill": {
     "duration": 2.649555,
     "end_time": "2023-01-30T12:36:35.088473",
     "exception": false,
     "start_time": "2023-01-30T12:36:32.438918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid data has shape (7683577, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>11830</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529</td>\n",
       "      <td>1105029</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530</td>\n",
       "      <td>264500</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098530</td>\n",
       "      <td>264500</td>\n",
       "      <td>1661119288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098530</td>\n",
       "      <td>409236</td>\n",
       "      <td>1661119369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session      aid          ts  type\n",
       "0  11098528    11830  1661119200     0\n",
       "1  11098529  1105029  1661119200     0\n",
       "2  11098530   264500  1661119200     0\n",
       "3  11098530   264500  1661119288     0\n",
       "4  11098530   409236  1661119369     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are reading Radek's validation files.\n",
    "# train = pd.read_parquet(\"../input/otto-train-and-test-data-for-local-validation/train.parquet\")\n",
    "valid = pd.read_parquet(\"../input/otto-train-and-test-data-for-local-validation/test.parquet\")\n",
    "valid_labels = pd.read_parquet(\"../input/otto-train-and-test-data-for-local-validation/test_labels.parquet\")\n",
    "print('valid data has shape',valid.shape)\n",
    "valid.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3d600",
   "metadata": {
    "papermill": {
     "duration": 0.010857,
     "end_time": "2023-01-30T12:36:35.110235",
     "exception": false,
     "start_time": "2023-01-30T12:36:35.099378",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "537ea5ec",
   "metadata": {
    "papermill": {
     "duration": 0.010467,
     "end_time": "2023-01-30T12:36:35.131365",
     "exception": false,
     "start_time": "2023-01-30T12:36:35.120898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create validations CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e889641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T12:36:35.154035Z",
     "iopub.status.busy": "2023-01-30T12:36:35.153723Z",
     "iopub.status.idle": "2023-01-30T13:06:26.217264Z",
     "shell.execute_reply": "2023-01-30T13:06:26.216273Z"
    },
    "papermill": {
     "duration": 1791.088115,
     "end_time": "2023-01-30T13:06:26.230044",
     "exception": false,
     "start_time": "2023-01-30T12:36:35.141929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved the cg outputs\n",
      "CPU times: user 29min 41s, sys: 13.6 s, total: 29min 54s\n",
      "Wall time: 29min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid = valid.sort_values([\"session\", \"ts\"])\n",
    "clicks_pred_df,carts_pred_df,orders_pred_df=pred_df_gen(valid)\n",
    "clicks_pred_df.to_parquet(f'valid_click_candidates_v{VER}.parquet')\n",
    "carts_pred_df.to_parquet(f'valid_carts_candidates_v{VER}..parquet')\n",
    "orders_pred_df.to_parquet(f'valid_buys_candidates_v{VER}..parquet')\n",
    "print('already saved the cg outputs')\n",
    "\n",
    "# # FREE MEMORY\n",
    "del clicks_pred_df,carts_pred_df,orders_pred_df,valid\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5636dd4",
   "metadata": {
    "papermill": {
     "duration": 0.011344,
     "end_time": "2023-01-30T13:06:26.573017",
     "exception": false,
     "start_time": "2023-01-30T13:06:26.561673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# validation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be36d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T13:06:26.596628Z",
     "iopub.status.busy": "2023-01-30T13:06:26.596257Z",
     "iopub.status.idle": "2023-01-30T13:10:31.964608Z",
     "shell.execute_reply": "2023-01-30T13:10:31.963705Z"
    },
    "papermill": {
     "duration": 245.39345,
     "end_time": "2023-01-30T13:10:31.977257",
     "exception": false,
     "start_time": "2023-01-30T13:06:26.583807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 58s, sys: 7.62 s, total: 4min 6s\n",
      "Wall time: 4min 5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528_clicks</td>\n",
       "      <td>11830 588923 1732105 571762 884502 876129 1157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529_clicks</td>\n",
       "      <td>1105029 217742 1694360 1544564 1383767 1729203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530_clicks</td>\n",
       "      <td>409236 264500 1603001 364155 583026 254154 877...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531_clicks</td>\n",
       "      <td>396199 1271998 452188 1728212 1365569 624163 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532_clicks</td>\n",
       "      <td>876469 7651 108125 1402537 659399 738098 24318...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  11098528_clicks  11830 588923 1732105 571762 884502 876129 1157...\n",
       "1  11098529_clicks  1105029 217742 1694360 1544564 1383767 1729203...\n",
       "2  11098530_clicks  409236 264500 1603001 364155 583026 254154 877...\n",
       "3  11098531_clicks  396199 1271998 452188 1728212 1365569 624163 1...\n",
       "4  11098532_clicks  876469 7651 108125 1402537 659399 738098 24318..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "clicks_pred_df=pd.read_parquet(f'valid_click_candidates_v{VER}.parquet')\n",
    "carts_pred_df=pd.read_parquet(f'valid_carts_candidates_v{VER}..parquet')\n",
    "orders_pred_df=pd.read_parquet(f'valid_buys_candidates_v{VER}..parquet')\n",
    "pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n",
    "del clicks_pred_df,carts_pred_df,orders_pred_df\n",
    "_ = gc.collect()\n",
    "pred_df.columns = [\"session_type\", \"labels\"]\n",
    "pred_df[\"labels\"] = pred_df.labels.apply(lambda x: \" \".join(map(str,x)))\n",
    "pred_df.to_csv(\"validation_preds.csv\", index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "822aa8c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T13:10:32.001578Z",
     "iopub.status.busy": "2023-01-30T13:10:32.001243Z",
     "iopub.status.idle": "2023-01-30T13:13:20.604512Z",
     "shell.execute_reply": "2023-01-30T13:13:20.603502Z"
    },
    "papermill": {
     "duration": 168.629732,
     "end_time": "2023-01-30T13:13:20.618297",
     "exception": false,
     "start_time": "2023-01-30T13:10:31.988565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks recall = 0.6542055010042528\n",
      "carts recall = 0.6197001814453877\n",
      "orders recall = 0.772893971650447\n",
      "=============\n",
      "Overall Recall = 0.7150669875243099\n",
      "=============\n",
      "CPU times: user 2min 44s, sys: 4.41 s, total: 2min 48s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# COMPUTE METRIC\n",
    "score = 0\n",
    "weights = {'clicks': 0.10, 'carts': 0.30, 'orders': 0.60}\n",
    "for t in ['clicks','carts','orders']:\n",
    "    sub = pred_df.loc[pred_df.session_type.str.contains(t)].copy()\n",
    "    sub['session'] = sub.session_type.apply(lambda x: int(x.split('_')[0]))\n",
    "    sub.labels = sub.labels.apply(lambda x: [int(i) for i in x.split(' ')])\n",
    "    test_labels = pd.read_parquet('../input/otto-validation/test_labels.parquet')\n",
    "    test_labels = test_labels.loc[test_labels['type']==t]\n",
    "    test_labels = test_labels.merge(sub, how='left', on=['session'])\n",
    "    test_labels = test_labels.dropna()\n",
    "    test_labels['hits'] = test_labels.apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n",
    "    test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n",
    "    recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "    score += weights[t]*recall\n",
    "    print(f'{t} recall =',recall)\n",
    "    \n",
    "print('=============')\n",
    "print('Overall Recall =',score)\n",
    "print('=============')\n",
    "# FREE MEMORY\n",
    "del test_labels,pred_df\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef7e5c",
   "metadata": {
    "papermill": {
     "duration": 0.011953,
     "end_time": "2023-01-30T13:13:20.641845",
     "exception": false,
     "start_time": "2023-01-30T13:13:20.629892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create test CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aed592a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T13:13:20.667036Z",
     "iopub.status.busy": "2023-01-30T13:13:20.666665Z",
     "iopub.status.idle": "2023-01-30T13:13:23.717929Z",
     "shell.execute_reply": "2023-01-30T13:13:23.716845Z"
    },
    "papermill": {
     "duration": 3.066809,
     "end_time": "2023-01-30T13:13:23.719969",
     "exception": false,
     "start_time": "2023-01-30T13:13:20.653160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data has shape (6928123, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13099779</td>\n",
       "      <td>245308</td>\n",
       "      <td>1661795832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13099779</td>\n",
       "      <td>245308</td>\n",
       "      <td>1661795862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13099779</td>\n",
       "      <td>972319</td>\n",
       "      <td>1661795888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13099779</td>\n",
       "      <td>972319</td>\n",
       "      <td>1661795898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13099779</td>\n",
       "      <td>245308</td>\n",
       "      <td>1661795907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session     aid          ts  type\n",
       "0  13099779  245308  1661795832     0\n",
       "1  13099779  245308  1661795862     1\n",
       "2  13099779  972319  1661795888     0\n",
       "3  13099779  972319  1661795898     1\n",
       "4  13099779  245308  1661795907     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test candidate generation \n",
    "type_labels = {'clicks':0, 'carts':1, 'orders':2}\n",
    "def load_test():    \n",
    "    dfs = []\n",
    "    for e, chunk_file in enumerate(glob.glob('../input/otto-chunk-data-inparquet-format/test_parquet/*')):\n",
    "        chunk = pd.read_parquet(chunk_file)\n",
    "        chunk.ts = (chunk.ts/1000).astype('int32')\n",
    "        chunk['type'] = chunk['type'].map(type_labels).astype('int8')\n",
    "        dfs.append(chunk)\n",
    "    return pd.concat(dfs).reset_index(drop=True) #.astype({\"ts\": \"datetime64[ms]\"})\n",
    "\n",
    "test_df = load_test()\n",
    "print('Test data has shape',test_df.shape)\n",
    "test_df.head()\n",
    "# top_clicks = test_df.loc[test_df['type']==0,'aid'].value_counts().index.values[:200]\n",
    "# top_orders = test_df.loc[test_df['type']==1,'aid'].value_counts().index.values[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd56d4",
   "metadata": {
    "papermill": {
     "duration": 0.011899,
     "end_time": "2023-01-30T13:13:23.743971",
     "exception": false,
     "start_time": "2023-01-30T13:13:23.732072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Test CG \n",
    "Inferring test data with Pandas groupby is slow. We need to accelerate the following code.Create Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "325e7179",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-30T13:13:23.769441Z",
     "iopub.status.busy": "2023-01-30T13:13:23.769149Z",
     "iopub.status.idle": "2023-01-30T13:41:40.674737Z",
     "shell.execute_reply": "2023-01-30T13:41:40.673698Z"
    },
    "papermill": {
     "duration": 1696.921422,
     "end_time": "2023-01-30T13:41:40.677044",
     "exception": false,
     "start_time": "2023-01-30T13:13:23.755622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved test cg \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred_df_clicks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:9\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_df_clicks' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = test_df.sort_values([\"session\", \"ts\"])\n",
    "clicks_pred_df,carts_pred_df,orders_pred_df=pred_df_gen(test_df)\n",
    "\n",
    "clicks_pred_df.to_parquet(f'test_click_candidates_v{VER}.parquet')\n",
    "carts_pred_df.to_parquet(f'test_carts_candidates_v{VER}.parquet')\n",
    "orders_pred_df.to_parquet(f'test_buys_candidates_v{VER}.parquet')\n",
    "print('already saved test cg ')\n",
    "\n",
    "del pred_df_clicks,pred_df_buys,clicks_pred_df,carts_pred_df,orders_pred_df,test_df\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47d9cc90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T13:41:40.706531Z",
     "iopub.status.busy": "2023-01-30T13:41:40.706174Z",
     "iopub.status.idle": "2023-01-30T13:41:40.717726Z",
     "shell.execute_reply": "2023-01-30T13:41:40.716427Z"
    },
    "papermill": {
     "duration": 0.028485,
     "end_time": "2023-01-30T13:41:40.719242",
     "exception": true,
     "start_time": "2023-01-30T13:41:40.690757",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 6)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3378\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn [17], line 1\u001b[0m\n    get_ipython().run_cell_magic('time', '', 'import pandas as pd\\nclicks_pred_df=pd.read_parquet(f\\'test_click_candidates_v{VER}.parquet\\')\\ncarts_pred_df=pd.read_parquet(f\\'test_carts_candidates_v{VER}.parquet\\')\\norders_pred_df=pd.read_parquet(f\\'test_buys_candidates_v{VER}.parquet\\')\\npred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\\ndel clicks_pred_df,carts_pred_df,orders_pred_df_v{VER}\\n_ = gc.collect()\\npred_df.columns = [\"session_type\", \"labels\"]\\npred_df[\"labels\"] = pred_df.labels.apply(lambda x: \" \".join(map(str,x)))\\npred_df.to_csv(\"test_preds.csv\", index=False)\\npred_df.head()\\n')\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2362\u001b[0m in \u001b[1;35mrun_cell_magic\u001b[0m\n    result = fn(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/usr/local/lib/python3.8/site-packages/IPython/core/magics/execution.py:1272\u001b[0m in \u001b[1;35mtime\u001b[0m\n    expr_ast = self.shell.compile.ast_parse(expr)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m/usr/local/lib/python3.8/site-packages/IPython/core/compilerop.py:105\u001b[0;36m in \u001b[0;35mast_parse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:6\u001b[0;36m\u001b[0m\n\u001b[0;31m    del clicks_pred_df,carts_pred_df,orders_pred_df_v{VER}\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "clicks_pred_df=pd.read_parquet(f'test_click_candidates_v{VER}.parquet')\n",
    "carts_pred_df=pd.read_parquet(f'test_carts_candidates_v{VER}.parquet')\n",
    "orders_pred_df=pd.read_parquet(f'test_buys_candidates_v{VER}.parquet')\n",
    "pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n",
    "del clicks_pred_df,carts_pred_df,orders_pred_df_v{VER}\n",
    "_ = gc.collect()\n",
    "pred_df.columns = [\"session_type\", \"labels\"]\n",
    "pred_df[\"labels\"] = pred_df.labels.apply(lambda x: \" \".join(map(str,x)))\n",
    "pred_df.to_csv(\"test_preds.csv\", index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd1202",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0bab4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4121.89877,
   "end_time": "2023-01-30T13:41:44.065475",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-30T12:33:02.166705",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
